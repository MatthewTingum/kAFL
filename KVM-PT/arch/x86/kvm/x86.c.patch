--- x86.c	2019-03-27 00:18:00.000000000 -0500
+++ x86.c.patched	2019-04-07 23:32:52.574650000 -0500
@@ -3176,6 +3176,12 @@
 		r = msr_io(NULL, argp, do_get_msr_feature, 1);
 		break;
 	}
+#ifdef CONFIG_KVM_VMX_PT
+	case KVM_VMX_PT_SUPPORTED: {
+		r = kvm_x86_ops->vmx_pt_enabled();
+		break;
+	}
+#endif
 	default:
 		r = -EINVAL;
 	}
@@ -4225,6 +4231,12 @@
 		r = 0;
 		break;
 	}
+#ifdef CONFIG_KVM_VMX_PT
+	case KVM_VMX_PT_SETUP_FD: {
+		r = kvm_x86_ops->setup_trace_fd(vcpu);
+		break;
+	}
+#endif
 	default:
 		r = -EINVAL;
 	}
@@ -7062,7 +7074,11 @@
 int kvm_emulate_hypercall(struct kvm_vcpu *vcpu)
 {
 	unsigned long nr, a0, a1, a2, a3, ret;
-	int op_64_bit;
+	int op_64_bit, r = 1;
+
+	// This was removed / rearranged here: https://github.com/torvalds/linux/commit/6356ee0c9602004e0a3b4b2dad68ee2ee9385b17#diff-2967f5c1784e6895cdae2b8dd100e68a
+	// Without it, our kAFL lock hypercall saves the VM state at the instruction pointer of the hypercall. Without it, when we loadvm it executes the hypercall and we're stuck
+	kvm_skip_emulated_instruction(vcpu);
 
 	if (kvm_hv_hypercall_enabled(vcpu->kvm))
 		return kvm_hv_hypercall(vcpu);
@@ -7083,8 +7099,86 @@
 		a2 &= 0xFFFFFFFF;
 		a3 &= 0xFFFFFFFF;
 	}
+	
+#ifdef CONFIG_KVM_VMX_PT
+	/* kAFL Hypercall Interface (ring 0) */
+	if(kvm_x86_ops->get_cpl(vcpu) == 0) {
+		r = 0;
+		if (kvm_register_read(vcpu, VCPU_REGS_RAX) == HYPERCALL_KAFL_RAX_ID){
+			switch(kvm_register_read(vcpu, VCPU_REGS_RBX)){
+				case 8: /* PANIC */   
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_PANIC;    
+					break;
+				case 9: /* KASAN */ 
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_KASAN; 
+					break;
+				default:
+					r = -KVM_EPERM;   
+					break;   
+			}
+			return r;
+		}
+	}
+#endif
 
 	if (kvm_x86_ops->get_cpl(vcpu) != 0) {
+		/* kAFL Hypercall interface */
+		#ifdef CONFIG_KVM_VMX_PT
+		if (kvm_register_read(vcpu, VCPU_REGS_RAX) == HYPERCALL_KAFL_RAX_ID){
+			r = 0;
+			switch(kvm_register_read(vcpu, VCPU_REGS_RBX)){
+				case 0:  /* KAFL_GUEST_ACQUIRE */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_ACQUIRE;
+					break;
+				case 1:  /* KAFL_GUEST_GET_PAYLOAD */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_GET_PAYLOAD;
+					vcpu->run->hypercall.args[0] = kvm_register_read(vcpu, VCPU_REGS_RCX);
+					break;
+				case 2:  /* KAFL_GUEST_GET_PROGRAM */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_GET_PROGRAM;
+					vcpu->run->hypercall.args[0] = kvm_register_read(vcpu, VCPU_REGS_RCX);
+					break;
+				case 3: /* KAFL_GUEST_GET_ARGV */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_GET_ARGV;
+					vcpu->run->hypercall.args[0] = kvm_register_read(vcpu, VCPU_REGS_RCX);
+					break;
+				case 4: /* KAFL_GUEST_RELEASE */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_RELEASE;
+					break;
+				case 5: /* KAFL_GUEST_SUBMIT_CR3 */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_SUBMIT_CR3;
+					vcpu->run->hypercall.args[0] = kvm_read_cr3(vcpu);
+					break;
+				case 6: /* KAFL_GUEST_PANIC */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_SUBMIT_PANIC;
+					vcpu->run->hypercall.args[0] = kvm_register_read(vcpu, VCPU_REGS_RCX); 
+					break;
+				case 7: /* KAFL_GUEST_KASAN */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_SUBMIT_KASAN;
+					vcpu->run->hypercall.args[0] = kvm_register_read(vcpu, VCPU_REGS_RCX); 
+					break;
+				case 10: /* LOCK */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_LOCK;
+					break;
+				case 11: /* INFO */    
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_INFO;
+                    vcpu->run->hypercall.args[0] = kvm_register_read(vcpu, VCPU_REGS_RCX);
+					break;
+				case 12: /* KAFL_GUEST_NEXT_PAYLOAD */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_NEXT_PAYLOAD;
+					break;
+				case 13: /* KAFL_GUEST_DEBUG */
+					vcpu->run->exit_reason = KVM_EXIT_KAFL_DEBUG;
+					vcpu->run->hypercall.args[0] = kvm_register_read(vcpu, VCPU_REGS_RCX);
+					break;
+				default:
+					r = -KVM_EPERM;
+					break;
+			}
+			return r;
+		}
+		#endif
+
 		ret = -KVM_EPERM;
 		goto out;
 	}
@@ -7115,7 +7209,8 @@
 	kvm_register_write(vcpu, VCPU_REGS_RAX, ret);
 
 	++vcpu->stat.hypercalls;
-	return kvm_skip_emulated_instruction(vcpu);
+	//return kvm_skip_emulated_instruction(vcpu);
+	return r;
 }
 EXPORT_SYMBOL_GPL(kvm_emulate_hypercall);
 
